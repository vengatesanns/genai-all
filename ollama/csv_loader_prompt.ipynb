{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV file, Convert it into embeddings, store in Redis Vectore Store and Do Similarity Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import redis\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load CSV and Preprocess\n",
    "def load_and_prepare_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Create a description for embedding\n",
    "    df['description'] = df.apply(\n",
    "        lambda row: f\"{row['bike_name']} in {row['city']} by {row['owner']} owner with {row['kms_driven']} km driven.\",\n",
    "        axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Step 2: Generate Embeddings\n",
    "def generate_embeddings(df, model):\n",
    "    embeddings = model.encode(df['description'].tolist())\n",
    "    return embeddings\n",
    "\n",
    "# Step 3: Store Embeddings and Metadata in Redis\n",
    "def store_embeddings_in_redis(df, embeddings, redis_client, index_name=\"bike_vector_index\"):\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        bike_data = {\n",
    "            \"bike_name\": df.loc[i, 'bike_name'],\n",
    "            \"price\": df.loc[i, 'price'],\n",
    "            \"city\": df.loc[i, 'city'],\n",
    "            \"kms_driven\": df.loc[i, 'kms_driven'],\n",
    "            \"owner\": df.loc[i, 'owner'],\n",
    "            \"age\": df.loc[i, 'age'],\n",
    "            \"power\": df.loc[i, 'power'],\n",
    "            \"brand\": df.loc[i, 'brand']\n",
    "        }\n",
    "        redis_client.hset(\n",
    "            f\"{index_name}:{i}\",\n",
    "            mapping={\n",
    "                \"embedding\": np.array(embedding).tobytes(),  # Store embedding as binary\n",
    "                \"metadata\": json.dumps(bike_data)  # Metadata as JSON string\n",
    "            }\n",
    "        )\n",
    "    redis_client.sadd(f\"{index_name}_keys\", *[f\"{index_name}:{i}\" for i in range(len(embeddings))])\n",
    "\n",
    "# Step 4: Perform Similarity Search\n",
    "def similarity_search(query_embedding, redis_client, index_name=\"bike_vector_index\", top_k=3):\n",
    "    # In a real scenario, use RediSearch or Approximate Nearest Neighbor libraries\n",
    "    all_keys = redis_client.smembers(f\"{index_name}_keys\")\n",
    "    results = []\n",
    "    for key in all_keys:\n",
    "        data = redis_client.hgetall(key)\n",
    "        embedding = np.frombuffer(data['embedding'], dtype=np.float32)\n",
    "        score = np.dot(query_embedding, embedding)  # Example: Cosine similarity\n",
    "        results.append((score, json.loads(data['metadata'])))\n",
    "    results.sort(reverse=True, key=lambda x: x[0])  # Sort by similarity score\n",
    "    return results[:top_k]\n",
    "\n",
    "# Step 5: Query Ollama for Additional Context\n",
    "def query_ollama(prompt, context):\n",
    "    from langchain.chat_models import Ollama\n",
    "    from langchain.schema import ChatMessage\n",
    "\n",
    "    model = Ollama(model=\"ollama3\")\n",
    "    response = model.chat(messages=[ChatMessage(content=context), ChatMessage(content=prompt)])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShow me bikes available in Delhi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode([user_query])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 18\u001b[0m search_results \u001b[38;5;241m=\u001b[39m \u001b[43msimilarity_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mredis_client\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Prepare context for Ollama\u001b[39;00m\n\u001b[0;32m     21\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBike: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbike_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Price: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, City: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m search_results])\n",
      "Cell \u001b[1;32mIn[5], line 45\u001b[0m, in \u001b[0;36msimilarity_search\u001b[1;34m(query_embedding, redis_client, index_name, top_k)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m all_keys:\n\u001b[0;32m     44\u001b[0m     data \u001b[38;5;241m=\u001b[39m redis_client\u001b[38;5;241m.\u001b[39mhgetall(key)\n\u001b[1;32m---> 45\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     46\u001b[0m     score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(query_embedding, embedding)  \u001b[38;5;66;03m# Example: Cosine similarity\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend((score, json\u001b[38;5;241m.\u001b[39mloads(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m])))\n",
      "\u001b[1;31mKeyError\u001b[0m: 'embedding'"
     ]
    }
   ],
   "source": [
    "# Main Workflow\n",
    "if __name__ == \"__main__\":\n",
    "    # File and model initialization\n",
    "    csv_path = r\"D:\\Projects\\genai-poc\\test_data_files\\Used_Bikes_With_Header.csv\"\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    redis_client = redis.Redis(host=\"localhost\", port=6379, decode_responses=True)\n",
    "\n",
    "    # Load and process data\n",
    "    df = load_and_prepare_data(csv_path)\n",
    "    embeddings = generate_embeddings(df, model)\n",
    "\n",
    "    # Store embeddings and metadata in Redis\n",
    "    store_embeddings_in_redis(df, embeddings, redis_client)\n",
    "\n",
    "    # User query and search\n",
    "    user_query = \"Show me bikes available in Delhi\"\n",
    "    query_embedding = model.encode([user_query])[0]\n",
    "    search_results = similarity_search(query_embedding, redis_client)\n",
    "\n",
    "    # Prepare context for Ollama\n",
    "    context = \"\\n\".join([f\"Bike: {result[1]['bike_name']}, Price: {result[1]['price']}, City: {result[1]['city']}\" for result in search_results])\n",
    "    response = query_ollama(user_query, context)\n",
    "\n",
    "    print(\"Ollama Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
